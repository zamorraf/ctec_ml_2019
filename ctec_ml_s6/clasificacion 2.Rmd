---
title: "Clase 6"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Tarea 6.
# Metodos supervisados 2

Librerias
```{r include=FALSE}
library(caTools)
library(rpart)
library(readr)
library(dplyr)
library(visdat)
library(ggplot2)

# Para la funcion sample.split
library(caTools)
# Para la funcion randomForest
library(randomForest)
# Para la funcion confusionMatrix
library(caret)
# Para la funcion rpart y rpart.plot
library(rpart)
library(rpart.plot)
# para la fucnion kknn
library(kknn)
# Para la función svm
library(e1071)
```

1. Desarolle el Análisis del Problema
```{r}
# Construya el análisis del problema


# Los datos se obtienen mediante el  parte oficial de tr?nsito que realiza la Direcci?n General de Polic?a de Tr?nsito al presentarse un accidente, los cuales ingresan a la base de datos de dos formas (hand held y papel). Debido a que parte de la labor principal de la Instituci?n es salvar vidas, y por los recursos limitados que existen, se trabaja solo con accidentes con heridos y/o fallecidos; y no se trabaja con accidentes que presentan solo da?os materiales. Adem?s, posteriormente inicia el proceso de limpieza, correcci?n de inconsistencias, validaci?n de algunas variables,  georeferenciaci?n de los accidentes, entre otros.


#Accidente con v?ctima se refiere cuando en el accidente de tr?nsito al menos uno de los participantes resulto: herido leve, grave o fallecido.

#Para m?s informaci?n revisar la metodolog?a del documento Memoria estad?stica de accidentes de tr?nsito con v?ctimas.Periodo 2012-2014.

```
Conjunto de datos que incluye información de de partes oficiales de tránsito al presentarse un acidente. De la información del parte se puede determinar si en el  accidente hubieron personas ilesas o hubieron víctimas. Lo que se trata de hacer, es demostrar como clasificar los accidentes para determinar si hubieron víctimas, ya que la función de la institución (Policía de Tránsito) es salvar vidas.


Fuente del dataset:
http://datosabiertos.csv.go.cr/dashboards/19683/accidentes/

1. Cargue el archivo nombre.csv en una variable

**Se identifica el conjunto de caracteres del archivo**
```{r}
# Identificar el conjunto de carácteres 
guess_encoding("temp_5571830814335439232.csv" )
```

**Se carga el archivo de datos**
```{r}
# Cargar el archivo
accidentes <- read.csv("temp_5571830814335439232.csv", encoding = "UTF-8", 
                       header = TRUE)
```

**Se asignan los nombres de las variables**
```{r}
# Se actualizan los nombres de variables
nombres_columna <- c("a_persona", "rol", "tipo_de_lesion", "edad", 
                     "edad_quinquenal", "sexo", "anno", "mes", "dia", "provincia",
                     "canton", "distrito", "dia_1", "mes_1", "edad_quinquenal_1")
colnames(accidentes) <- nombres_columna
colnames(accidentes)
```

**Se eliminan las variables que no se requieren**
```{r}
# Eliminar las variables que no se necesitan
accidentes <- accidentes %>% 
                select(-a_persona, -dia_1, -mes_1, -edad_quinquenal_1)
```
Se eliminan las siguientes variables:
  a_persona: posee un valor único.
  dia_1: corresponde a la variable día.
  mes_1: corresponde a la variable mes.
  edad_quincenal_1: corresponde a la variables edad_quincenal


**Se asignan las etiquetas a las variables de tipo factor**
```{r}
#accidentes$anno <- 
#  factor(accidentes$anno, levels = c("2013","2014","2015","2016","2017"), 
#         labels = c("2013","2014","2015","2016","2017"), ordered = TRUE)

accidentes$mes <- 
  factor(accidentes$mes, levels = c("Enero","Febrero","Marzo","Abril","Mayo",
                                    "Junio","Julio","Agosto","Setiembre",
                                    "Octubre","Noviembre", "Diciembre"),
         labels = c("Enero","Febrero","Marzo","Abril","Mayo","Junio","Julio",
                    "Agosto","Septiembre","Octubre","Noviembre", "Diciembre"),
         ordered = TRUE)

accidentes$provincia <- 
  factor(accidentes$provincia, levels = c("San José","Alajuela","Cartago",
                                          "Heredia","Guanacaste","Puntarenas",
                                          "Limón"))
```

**Se identifica la variable objetivo**
```{r}
# Se revisa la variable tipo_de_lesion para identificar las clases que la componen 
table(accidentes$tipo_de_lesion)

#Se crea una variable binaria que identifica la clase de accidente (si hubieron víctimas).
accidentes <- accidentes %>% 
                mutate(clase_accidente = 
                         ifelse (tipo_de_lesion == "Ileso", "Ileso","Víctima"))

# Se convierte a factor la nueva variable
accidentes$clase_accidente <- 
  factor(accidentes$clase_accidente, levels = c("Víctima","Ileso"))

# Se valida la cantidad de observaciones
table(accidentes$clase_accidente)
```

**Imputacion de datos**
```{r}
# Se imputa el valor desconocido de la variable edad por el promedio
accidentes$edad.mean <- 
  ifelse(accidentes$edad == "Desconocido", NA, accidentes$edad)
accidentes$edad.mean <- 
  ifelse(is.na(accidentes$edad.mean),
         round(mean(accidentes$edad.mean, na.rm = TRUE),digits = 0),
         accidentes$edad.mean)
```


2. Desarolle el Entendimiento de los Datos

**Se identifican las variables y sus tipos de datos**
```{r}
glimpse(accidentes)
```
Existen 11 variables que son factores, 2 enteras.

En la variable edad.mean se almacena la imputación de la variable edad con el valor promedio para las edades con valor "desconocido".

Se utiliza la variable "clase_accidente" como variable objetivo, posee dos valores: Víctima e Ileso.


**Se realiza un resumen de cada variable**
```{r}
summary(accidentes)
```

**Se identifican los tipos de datos de las observaciones**
```{r}
#vis_dat(accidentes, warn_large_data = FALSE)
```


**Se identifica la cantidad de clases de cada una de las variables**
```{r}
# Calcula el número de clases para cada variable
as_tibble(arrange(cbind.data.frame(Variables=names(accidentes), 
                 Numero_Clases=sapply(accidentes,
                                      function(x){as.numeric(length(levels(x)))})),-Numero_Clases))
```


3. Utilizando barplot cree un gr?fico de los atributos del dataset, observe las correlaciones entre atributos

**Se analizan las variables más representativas**
```{r}
#barplot(table(accidentes$clase_accidente), main = "Distribución de Accidentes", 
#        ylab = "Observaciones", xlab = "Hay Víctimas?")

ggplot(as.data.frame(table(accidentes$clase_accidente)), aes(x=Var1, y=Freq)) + 
  geom_bar(stat = "identity") + 
  xlab("Clase de Accidente") + ylab("Observaciones") + 
  ggtitle("Distribución de Accidentes")  + theme_light()  +
  theme(plot.title = element_text(face = "bold", hjust = 0.5))
```

```{r fig.width = 10}
# Accidentes por rol
ggplot(as.data.frame(table(accidentes$clase_accidente, accidentes$rol)),
       aes(x = Var2 , y = Freq, fill = Var1 )) +
  geom_bar(stat = "identity")  +
  #coord_flip() + 
  xlab("Rol") + ylab("Cantidad") + 
  ggtitle("Distribución de Clases de Accidente por Rol")  + theme_light() + 
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
        axis.text.x = element_text(angle=45, vjust=1, hjust=1)) +
  guides(fill=guide_legend(title="Clase Accidente"))
```


```{r  fig.width = 10}
# Anàlisis de la variable provincia
ggplot(accidentes,
  aes(x = provincia, fill= clase_accidente  ))+
  geom_bar(position = position_dodge2())+  
  xlab("Provincia") + ylab("Cantidad") + 
  ggtitle("Distribución de Accidentes por Provincia")  + theme_light() + 
  theme(plot.title = element_text(face = "bold", hjust = 0.5)) +
  guides(fill=guide_legend(title="Clase Accidente"))

```



4. Realice al menos 5 modelos de los observados en clase

**División de los datos de prueba y entrenamiento**
```{r}
set.seed(201909)
split <- sample.split(accidentes$clase_accidente, SplitRatio = 0.8 )
entrena <- subset(accidentes, split == TRUE)
prueba <- subset(accidentes, split == FALSE)

```

**Cantidad de observaciones en el conjunto de prueba (FALSE) y el de entrenamiento (TRUE)**
```{r}
table(accidentes$clase_accidente, split)
```

**Creación de modelo utilizando método Random Forest**
```{r}
#Random Forest
modelo_bosque <- randomForest(clase_accidente ~ rol + provincia + anno + sexo + 
                              edad_quinquenal, data = entrena)
modelo_bosque
plot(modelo_bosque)
```
El método Random Forest predice con 84.92% de precisión (15.08% de error).
El modelo muestra que de un total de 126,719 observaciones de entrenamiento 61,553 son Víctima y 46,054 son Ilesos

**Creación de modelo utilizando método Arboles de decisión**
```{r}
# Arbol de decisiones 
modelo_arbol <- rpart(clase_accidente ~ edad_quinquenal + rol + mes + provincia + 
                      sexo, data = entrena, method =  'class')
modelo_arbol
```
```{r fig.width = 10}
rpart.plot(modelo_arbol, shadow.col = "gray", extra = 104, 
           main = "Clasificación de Accidentes por Clase de Accidente")
```
De una cantidad de 126,719 observaciones de entrenamiento, para los accidentes el 53% tiene víctimas y el 47% salen ilesos. Representado en cantidades 67030 vícitimas y 59689 ilesos.


**Creación de modelo utilizando método SVM**
```{r}
modelo_svm <- svm(clase_accidente ~ rol, cost = 1, gamma = 0.01,
                  data = entrena[,names(entrena) %in% c("clase_accidente","rol")])
modelo_svm
```


**Creación del modelo utilizando método de KNN (vecinos más cercanos )**
```{r}
modelo_knn <- kknn(clase_accidente ~ rol + provincia , train = entrena, 
                   test = prueba, k = 4)
```


**Creación del modelo de red neuronal**
```{r}
modelo_neuronal <- 
  nnet::nnet(clase_accidente ~ rol + sexo + provincia , data = entrena,
              size = 2, maxit = 10000, decay = 0.001, rang = 0.05, 
              na.action = na.omit, skip = TRUE)
```



5. Evaluaci?n de los modelos

**Evaluación del modelo Random Forest** 
```{r}
#Random Forest
predic_bosque <- predict(modelo_bosque, newdata = prueba, type = 'class')

table(predic_bosque, prueba$clase_accidente)

confusionMatrix(data = predic_bosque, reference = prueba$clase_accidente,
                       positive = "Víctima" )

```

**Evaluación del modelo Arbol de decisión**
```{r}
predic_arbol <- predict(modelo_arbol, newdata = prueba, type = 'class')
table(predic_arbol ,prueba$clase_accidente )

confusionMatrix(data = predic_arbol, reference = prueba$clase_accidente,
                positive = "Víctima" )
```

**Evaluación de modelo SVM**
```{r}
predic_svm <- predict(modelo_svm, newdata = prueba, type = 'class')
table(predic_svm, prueba$clase_accidente)

caret::confusionMatrix(data = predic_svm, reference = prueba$clase_accidente,
                       positive = "Víctima" )
```


**Evaluación del modelo KNN (vecinos más cercanos )**
```{r}
fit <- fitted(modelo_knn)

confusionMatrix(prueba$clase_accidente, fit, positive = "Víctima")
```

**Evaluación del modelo de la red neuronal**
```{r}
pedict_neuronal <- predict(modelo_neuronal, newdata = prueba, type = "class")

table(prueba$clase_accidente, pedict_neuronal, dnn = c("Actual","Predicho"))

confusionMatrix( data = factor(pedict_neuronal), reference = prueba$clase_accidente, 
                positive = "Víctima")
```


6. Desarolle al menos 5 conclusiones sobre las clasificaciones de los modelos

Para el modelo creado con el método de Bosque Aleatorio, presenta la precisión es exacta, alcanza el 84.69%.

Para el modelo creado con el método de arbol de decisión, SVM y red neuronal toman una precisión del 84.68% aunque difieren en el porcentaje de error por 0.0001%.

El metodo de arboles de decision presenta una salida que es mas fácil de comprender que los dos otros métodos, debido a que se muestra en forma gráfica mediante un árbol, que es mucho más fácil de leer.

Las variables mas importantes para los modelos son: rol.

De acuerdo a los datos de prueba y cada metodo aplicado, las predicciones indican lo siguiente:

|           MODELO                | PRECISIÓN | ERROR  |SENSIBILIDAD|ESPECIFICIDAD|
|---------------------------------| ----------| -------|------------|-------------|
|Random Forest                    | 84.69%    | 15.31% | 81.49%     | 83.96%      |
|Arbol de decisión                | 84.68%    | 15.32% | 81.44%     | 89.40%      |
|SVM Máquinas de soporte vectorial| 84.68%    | 15.32% | 81.44%     | 89.40%      |
|KNN Vecinos más cercanos         | 81.52%    | 18.48% | 85.07%     | 76.59%      |
|Red Neuronal                     | 84.68%    | 15.32% | 81.43%     | 89.41%      |
||

De acuerdo a la matriz de confusión se obtiene lo siguiente

|                                 | ACIERTOS  |        | FALLOS     |             |
|---------------------------------| ----------| -------|------------|-------------|
|           MODELO                | VÍCTIMAS  | ILESOS | VÍCTIMAS   | ILESOS      |
|Random Forest                    | 15,306    | 11,525 |    1,372   |  3,477      |
|Arbol de decisión                | 15,296    | 11,530 |    1,367   |  3,487      |
|SVM Máquinas de soporte vectorial| 15,296    | 11,530 |    1,367   |  3,487      |
|KNN Vecinos más cercanos         | 15,683    | 10,144 |    3,100   |  2,573      |
|Red Neuronal                     | 15,295    | 11,531 |    1,366   |  3,488      |
||
||
